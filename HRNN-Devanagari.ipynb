{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "# Import various componenets for model building\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import LSTM, Input, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Import the backend\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/aaronmichaelbroderick/Desktop/Data Science/Data/devanagari.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['character']\n",
    "\n",
    "columns = list(data)\n",
    "columns.remove('character')\n",
    "X = data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change strings into numerical to work well with Keras\n",
    "\n",
    "letters = list(set(Y))\n",
    "Y_test = list(Y)\n",
    "\n",
    "for i in range(len(letters)):\n",
    "    for j in range(len(Y_test)):\n",
    "        if letters[i] == Y_test[j]:\n",
    "            Y_test[j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['cat'] = Y\n",
    "results['num'] = Y_test\n",
    "\n",
    "Y = results.num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainD, x_testD, y_trainD, y_testD = train_test_split(X,Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters.\n",
    "batch_size = 64\n",
    "num_classes = 46\n",
    "epochs = 3\n",
    "\n",
    "# Embedding dimensions.\n",
    "row_hidden = 32\n",
    "col_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes the data from a pandas dataframe to a numpy array\n",
    "x_trainD = x_trainD.values\n",
    "x_testD = x_testD.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_trainD shape: (73600, 32, 32, 1)\n",
      "73600 train samples\n",
      "18400 test samples\n"
     ]
    }
   ],
   "source": [
    "# Reshapes data to 4D for Hierarchical RNN.\n",
    "x_trainD = x_trainD.reshape(x_trainD.shape[0], 32, 32, 1)\n",
    "x_testD = x_testD.reshape(x_testD.shape[0], 32, 32, 1)\n",
    "x_trainD = x_trainD.astype('float32')\n",
    "x_testD = x_testD.astype('float32')\n",
    "x_trainD /= 255\n",
    "x_testD /= 255\n",
    "print('x_trainD shape:', x_trainD.shape)\n",
    "print(x_trainD.shape[0], 'train samples')\n",
    "print(x_testD.shape[0], 'test samples')\n",
    "\n",
    "# Converts class vectors to binary class matrices.\n",
    "y_trainD = keras.utils.to_categorical(y_trainD, num_classes)\n",
    "y_testD = keras.utils.to_categorical(y_testD, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_3:0' shape=(?, 32, 32, 1) dtype=float32>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row, col, pixel = x_trainD.shape[1:]\n",
    "x = Input(shape=(row, col, pixel))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'time_distributed_3/Reshape_1:0' shape=(?, 32, 32) dtype=float32>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_rows = TimeDistributed(LSTM(row_hidden))(x)\n",
    "encoded_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstm_6/TensorArrayReadV3:0' shape=(?, 32) dtype=float32>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_columns = LSTM(col_hidden)(encoded_rows)\n",
    "encoded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18400, 46)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 73600 samples, validate on 18400 samples\n",
      "Epoch 1/3\n",
      "73600/73600 [==============================] - 149s 2ms/step - loss: 2.9287 - acc: 0.2180 - val_loss: 2.2810 - val_acc: 0.3704\n",
      "Epoch 2/3\n",
      "73600/73600 [==============================] - 149s 2ms/step - loss: 1.7789 - acc: 0.4951 - val_loss: 1.4156 - val_acc: 0.6042\n",
      "Epoch 3/3\n",
      "73600/73600 [==============================] - 148s 2ms/step - loss: 1.1507 - acc: 0.6703 - val_loss: 0.9778 - val_acc: 0.7188\n",
      "Test loss: 0.9778406575451727\n",
      "Test accuracy: 0.7188043478260869\n"
     ]
    }
   ],
   "source": [
    "# Final predictions and model.\n",
    "prediction = Dense(num_classes, activation='softmax')(encoded_columns)\n",
    "model = Model(x, prediction)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training.\n",
    "model.fit(x_trainD, y_trainD,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_testD, y_testD))\n",
    "\n",
    "# Evaluation.\n",
    "scores = model.evaluate(x_testD, y_testD, verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
