{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "# Import various componenets for model building\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import LSTM, Input, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Import the backend\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/aaronmichaelbroderick/Desktop/Data Science/Data/devanagari.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['character']\n",
    "\n",
    "columns = list(data)\n",
    "columns.remove('character')\n",
    "X = data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change strings into numerical to work well with Keras\n",
    "\n",
    "letters = list(set(Y))\n",
    "Y_test = list(Y)\n",
    "\n",
    "for i in range(len(letters)):\n",
    "    for j in range(len(Y_test)):\n",
    "        if letters[i] == Y_test[j]:\n",
    "            Y_test[j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['cat'] = Y\n",
    "results['num'] = Y_test\n",
    "\n",
    "Y = results.num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73600 train samples\n",
      "18400 test samples\n"
     ]
    }
   ],
   "source": [
    "# Convert to float32 for type consistency\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize values to 1 from 0 to 255 (256 values of pixels)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Print sample sizes\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "# So instead of one column with 10 values, create 10 binary columns\n",
    "y_train = keras.utils.to_categorical(y_train, 46)\n",
    "y_test = keras.utils.to_categorical(y_test, 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.values\n",
    "x_test = x_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (73600, 32, 32, 1)\n",
      "73600 train samples\n",
      "18400 test samples\n",
      "Train on 73600 samples, validate on 18400 samples\n",
      "Epoch 1/10\n",
      "73600/73600 [==============================] - 172s 2ms/step - loss: 1.2450 - acc: 0.6527 - val_loss: 0.2744 - val_acc: 0.9224\n",
      "Epoch 2/10\n",
      "73600/73600 [==============================] - 165s 2ms/step - loss: 0.4461 - acc: 0.8665 - val_loss: 0.1669 - val_acc: 0.9510\n",
      "Epoch 3/10\n",
      "73600/73600 [==============================] - 160s 2ms/step - loss: 0.3189 - acc: 0.9037 - val_loss: 0.1308 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      "73600/73600 [==============================] - 160s 2ms/step - loss: 0.2533 - acc: 0.9223 - val_loss: 0.1117 - val_acc: 0.9676\n",
      "Epoch 5/10\n",
      "73600/73600 [==============================] - 159s 2ms/step - loss: 0.2148 - acc: 0.9336 - val_loss: 0.1062 - val_acc: 0.9691\n",
      "Epoch 6/10\n",
      "73600/73600 [==============================] - 389s 5ms/step - loss: 0.1840 - acc: 0.9429 - val_loss: 0.0948 - val_acc: 0.9718\n",
      "Epoch 7/10\n",
      "73600/73600 [==============================] - 165s 2ms/step - loss: 0.1639 - acc: 0.9502 - val_loss: 0.0917 - val_acc: 0.9735\n",
      "Epoch 8/10\n",
      "73600/73600 [==============================] - 167s 2ms/step - loss: 0.1512 - acc: 0.9521 - val_loss: 0.0910 - val_acc: 0.9738\n",
      "Epoch 9/10\n",
      "73600/73600 [==============================] - 176s 2ms/step - loss: 0.1380 - acc: 0.9570 - val_loss: 0.0815 - val_acc: 0.9762\n",
      "Epoch 10/10\n",
      "73600/73600 [==============================] - 193s 3ms/step - loss: 0.1255 - acc: 0.9610 - val_loss: 0.0784 - val_acc: 0.9777\n",
      "Test loss: 0.07844698453625745\n",
      "Test accuracy: 0.9777173913043479\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions, from our data\n",
    "img_rows, img_cols = 32, 32\n",
    "num_classes = 46\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Building the Model\n",
    "model = Sequential()\n",
    "# First convolutional layer, note the specification of shape\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
